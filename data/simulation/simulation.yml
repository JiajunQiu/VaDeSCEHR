pre_training:
  seq_length: 100
  hidden_size: 100
  hidden_dropout_prob: 0
  num_hidden_layers: 3
  num_attention_heads: 10
  attention_probs_dropout_prob: 0
  intermediate_size: 1024
  hidden_act: 'gelu'

training:
  # Architecture
  monte_carlo: 1
  dropout_prob: 0
  latent_dim: 5
  learning_rate: 0.01
  weight_decay: 0.05
  max_epoch: 200
  num_clusters: 3
  num_reshape_layers: 1

  learn_prior: True
  weibull_shape: 1
  survival: True
  sample_surv: True